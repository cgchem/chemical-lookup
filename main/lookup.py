import xml.etree.ElementTree as ET
import time
import requests
import urllib
from collections import defaultdict
from main.xml import *


def GetFTPLink(query_text):

    """Sends an XML request (query_text) to PUG.cgi, and waits to recieve a link to
    the FTP address where the prepared SDfile containing all the structures can be downloaded.
    It's useful to be able to pass in different kinds of XML query text that might
    need to be generated by different functions."""

    def GetReqId(somexml, attrib):

        '''Small function to retrieve the first element with the corresponding name from some XML as a string,
        we want "PCT-Waiting_reqid" or "PCT-Download-URL_url" or "PCT-Status-Message_status"'''

        xml = ET.fromstring(somexml)
        for i in xml.iter():
            # iterate through all elements, return the first one that matches what we want
            j = i.find(attrib)
            if j is not None:
                return j.text
        return None

    first_response = requests.post(PUGURL, query_text)  # returns the job ID to poll for while waiting

    jobid = GetReqId(first_response.text, "PCT-Waiting_reqid")

    if jobid is None:  # sometimes the search completes instantly for small lists
        # in this case there will be no XML element called "PCT-Waiting_reqid"
        # so let's look for the download link instead
        already_done = GetReqId(first_response.text, "PCT-Download-URL_url")

        if already_done is not None:
            return already_done
        else:
            # neither the download URL or key was found, something is wrong
            print("Error submitting xml query")
            print(first_response.text)  # look at the response to see what went wrong

    # if we didn't already get the link, looks like we'll have to wait a bit longer:
    start_time = time_now = time.time()  # for checking time spent in the loop
    while time_now < start_time + 900:
        # enter loop to wait for completion of request, but bail out if it takes too long
        time_now = time.time()
        time.sleep(5)  # let's not hassle the server too often
        #  poll PUG to see whether the job has completed
        doneyet = requests.post(PUGURL, POLL_QUERY.format(jobid))
        #  check if the response contains a download link for the prepared SDF
        resultlink = GetReqId(doneyet.text, "PCT-Download-URL_url")
        if resultlink:
            return resultlink


def BuildQuery(list_of_names):

    '''Takes list of names and inserts them into the XML query text to post to PUG
    same as the previous function but uses the above XML strings instead. It would
    be even more general and better to make a function that takes arbitrary
    XML format strings as arguments and assembles the query appropriately.'''

    list_of_names = [str(x) for x in list_of_names]  # make sure they are strings

    small_queries = map(NAME_SMALL.format, list_of_names)  # make the individual XML queries per cid
    query_string = "\n".join(small_queries)  # join them together for insertion into the main template
    query_xml = NAME_XML_QUERY.format(query_string)  # insert joined block into main template

    return query_xml  # the formed xml query ready to be POSTed to pubchem


def read_from_ftp(link):

    out = defaultdict(list)

    filename, headers = urllib.request.urlretrieve(link)

    with open(filename, "r") as f:
        for line in f.readlines():
            try:
                a, b = (line.split("\t"))
            except ValueError:
                # couldn't split a line which means probably we just got an empty file
                return out
            out[a].append(b)

    return out


def names_to_synonyms(als):

    out = []

    ftp = GetFTPLink(BuildQuery([str(x) for x in als]))
    res = read_from_ftp(ftp)

    for q in als:
        out.append((q, res[q]))  # a list of tuples (name, [list_of_synonyms])
        # have to do it this way rather than just return the dict because the user might have submitted a list with
        # duplicates. And if we drop dupes, then the output list will be a different length to the input list which
        # will screw up the 1:1 mapping of columns in a spreadsheet

    # return res  # a dict of name: synonym (OLD METHOD)
    return out
